{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method takes the input file name and returns the text from whole file\n",
    "# If the notebook and file toread are not in the same directory, the whole path with file name is required\n",
    "def load_file(filename):\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method creates list of pair of sentences where each sentence is a list of token\n",
    "def generatePair(text1, text2):\n",
    "    pairs = []\n",
    "    text1 = text1.lower().strip().split(\"\\n\")\n",
    "    text2 = text2.lower().strip().split(\"\\n\")\n",
    "    for index, eSentence in enumerate(text1):\n",
    "        pairs.append((text2[index].split(), text1[index].split()))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method generates all translation probability using IBM 1 model\n",
    "# it iterates until all translation probability difference(previous and current) are less than a threshold \n",
    "def calculateTranslationProbability(pairs, threshold):\n",
    "    currentTranslationProbability = calculateUniformTranslationProbabilities(pairs)\n",
    "    previousTranslationProbability = {}\n",
    "    \n",
    "    iteratoinCount =0;\n",
    "    while not IsTranslationProbConverged(previousTranslationProbability, currentTranslationProbability, threshold):\n",
    "        previousTranslationProbability = currentTranslationProbability.copy()\n",
    "        \n",
    "        countFE = {}\n",
    "        totalE = {}\n",
    "        #Initialize all count(f,e) and total(e) to 0\n",
    "        for pair in pairs:\n",
    "            for wordF in pair[0]:\n",
    "                for wordE in pair[1]:\n",
    "                    countFE[wordF + \"|\" + wordE] = 0\n",
    "                    totalE[wordE] = 0\n",
    "        for pair in pairs:\n",
    "            for wordF in pair[0]:\n",
    "                sumF = 0\n",
    "                for wordE in pair[1]:\n",
    "                    sumF += currentTranslationProbability[wordF + \"|\" + wordE]\n",
    "                for wordE in pair[1]:\n",
    "                    countFE[wordF + \"|\" + wordE] += (currentTranslationProbability[wordF + \"|\" + wordE] / sumF)\n",
    "                    totalE[wordE] +=  (currentTranslationProbability[wordF + \"|\" + wordE] / sumF)\n",
    "        for key in currentTranslationProbability:\n",
    "            tmpKeys = key.split('|')\n",
    "            currentTranslationProbability[key] = countFE[key] / totalE[tmpKeys[1]]\n",
    "        iteratoinCount += 1\n",
    "#        if iteratoinCount % 100 == 0:\n",
    "#            print(\"************Current Iteration Count: \", iteratoinCount)\n",
    "    return currentTranslationProbability;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method generates initial posterior probability P(f|e) uniformly \n",
    "# by counting count(f,e) and count(e) in the whole data set\n",
    "def calculateUniformTranslationProbabilities(pairs):\n",
    "    uniformPosterior = {}\n",
    "    FECount = {}\n",
    "    ECount = {}\n",
    "    for pair in pairs:\n",
    "        for wordF in pair[0]:\n",
    "            for wordE in pair[1]:\n",
    "                key = wordF + \"|\" + wordE\n",
    "                if key in FECount.keys():\n",
    "                    FECount[key] += FECount[key]\n",
    "                else:\n",
    "                    FECount[key] = 1\n",
    "                    \n",
    "                if wordE in ECount.keys():\n",
    "                    ECount[wordE] += 1\n",
    "                else:\n",
    "                    ECount[wordE] = 1\n",
    "    \n",
    "    for pair in pairs:\n",
    "        for wordF in pair[0]:\n",
    "            for wordE in pair[1]:\n",
    "                key = wordF + \"|\" + wordE\n",
    "                try:\n",
    "                    uniformPosterior[key] = FECount[key] / ECount[wordE]\n",
    "                except:\n",
    "                    uniformPosterior[key] = 0.000001\n",
    "\n",
    "    return uniformPosterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method checks whether two translation probability dictionary are \n",
    "# equal or within a threshold difference or not\n",
    "def IsTranslationProbConverged(previousTranslationProbabilities, currentTranslationProbabilities, threshold):\n",
    "    if(len(previousTranslationProbabilities) == 0 or len(currentTranslationProbabilities) == 0):\n",
    "        return False\n",
    "    if previousTranslationProbabilities == currentTranslationProbabilities:\n",
    "        return True\n",
    "    else:\n",
    "        for key in previousTranslationProbabilities:\n",
    "            if abs(previousTranslationProbabilities[key] - currentTranslationProbabilities[key]) > threshold :\n",
    "                return False\n",
    "            \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method reuturns the best alignment of word in a pair of sentence\n",
    "def calculateAlignment(translationProbability, pairs):\n",
    "    \n",
    "    alignedWordList = []\n",
    "    alignedWordIndextList = []\n",
    "    for pair in pairs:\n",
    "        alignedWordListPerPair = dict()\n",
    "        alignedWordIndextListPerPair = []\n",
    "        for index1, wordF in enumerate(pair[0]):\n",
    "            bestAlignment = 0;\n",
    "            bestAligedWord = \"\"\n",
    "            bestAligedWordIndex = 0\n",
    "            \n",
    "            for index2, wordE in enumerate(pair[1]):\n",
    "                key = wordF + \"|\" + wordE\n",
    "                if translationProbability[key] > bestAlignment :\n",
    "                    bestAlignment = translationProbability[key]\n",
    "                    bestAligedWord = wordE\n",
    "                    bestAligedWordIndex = index2\n",
    "                    \n",
    "            alignedWordListPerPair[(wordF, bestAligedWord)] = bestAlignment\n",
    "            alignedWordIndextListPerPair. append((index1, bestAligedWordIndex))\n",
    "            \n",
    "        alignedWordList.append(alignedWordListPerPair)\n",
    "        alignedWordIndextList.append(alignedWordIndextListPerPair)\n",
    "        \n",
    "    return alignedWordList, alignedWordIndextList\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "germanText = load_file('de-en/de-en.de')\n",
    "englishText = load_file('de-en/de-en.en')\n",
    "pairs = generatePair(englishText, germanText)\n",
    "\n",
    "# 0.0001 is the threshold to measure convergence\n",
    "translationProb = calculateTranslationProbability(pairs[:100], 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and Data Sturcture used\n",
    "All of the translation probabilities are stored in a dictionary with key as string of f|e . Since using a sparse matrix will take more space, i used here dictionary. For spare matrix, it will take (numberUniqueofEnglishword * numberOfUniqueGermanWord) cells\n",
    "\n",
    "The IBM 1 model is ran on 100 sentence pair. Please change line 6 above **translationProb = calculateTranslationProbability(pairs[:100], 0.0001)** to **translationProb = calculateTranslationProbability(pairs, 0.0001)** to run it for all sentence pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment Probability::  {('wiederaufnahme', 'resumption'): 0.9993893603259384, ('der', 'of'): 0.7526721556935149, ('sitzungsperiode', 'session'): 0.9999999994181575}\n",
      "Alignment::  [(0, 0), (1, 1), (2, 3)]\n",
      "Alignment Probability::  {('ich', 'i'): 1.0, ('erkläre', 'declare'): 0.05783786644749496, ('die', 'the'): 0.2616889385112021, ('am', 'on'): 0.2698306407656617, ('freitag', 'declare'): 0.05783786644749496, (',', ','): 1.0, ('dem', 'wish'): 0.48377630550734607, ('17.', 'declare'): 0.05783786644749496, ('dezember', 'declare'): 0.05783786644749496, ('unterbrochene', 'declare'): 0.05783786644749496, ('sitzungsperiode', 'session'): 0.9999999994181575, ('des', 'year'): 0.7340922757519008, ('europäischen', 'european'): 1.0, ('parlaments', 'declare'): 0.05783786644749496, ('für', 'period'): 0.8505566148302802, ('wiederaufgenommen', 'declare'): 0.05783786644749496, ('wünsche', 'declare'): 0.05783786644749496, ('ihnen', 'declare'): 0.05783786644749496, ('nochmals', 'once'): 0.22919728167758996, ('alles', 'declare'): 0.05783786644749496, ('gute', 'declare'): 0.05783786644749496, ('zum', 'declare'): 0.05783786644749496, ('jahreswechsel', 'declare'): 0.05783786644749496, ('und', 'and'): 1.0, ('hoffe', 'hope'): 0.9646912337156369, ('daß', 'once'): 0.77080271832241, ('sie', 'you'): 0.9999985337259996, ('schöne', 'declare'): 0.05783786644749496, ('ferien', 'declare'): 0.05783786644749496, ('hatten', 'declare'): 0.05783786644749496, ('.', '.'): 1.0}\n",
      "Alignment::  [(0, 0), (1, 1), (2, 3), (3, 10), (4, 1), (5, 15), (6, 23), (7, 1), (8, 1), (9, 1), (10, 4), (11, 28), (12, 7), (13, 1), (14, 38), (15, 1), (16, 15), (17, 1), (18, 1), (19, 20), (20, 1), (21, 1), (22, 1), (23, 1), (24, 16), (25, 31), (26, 15), (27, 20), (28, 24), (29, 1), (30, 1), (31, 1), (32, 39)]\n",
      "Alignment Probability::  {('wie', 'although'): 0.5298956880566635, ('sie', 'you'): 0.9999985337259996, ('feststellen', 'seen'): 0.061827983226750184, ('konnten', 'seen'): 0.061827983226750184, (',', ','): 1.0, ('ist', 'number'): 0.5924744294974297, ('der', 'of'): 0.7526721556935149, ('gefürchtete', 'seen'): 0.061827983226750184, ('\"', 'seen'): 0.12365596645350037, ('millenium-bug', 'seen'): 0.061827983226750184, ('nicht', 'were'): 0.6492862005520721, ('eingetreten', 'seen'): 0.061827983226750184, ('.', '.'): 1.0, ('doch', 'seen'): 0.061827983226750184, ('sind', 'seen'): 0.061827983226750184, ('bürger', 'seen'): 0.061827983226750184, ('einiger', 'countries'): 0.7379475810061734, ('unserer', 'seen'): 0.061827983226750184, ('mitgliedstaaten', 'seen'): 0.061827983226750184, ('opfer', 'seen'): 0.061827983226750184, ('von', \"'\"): 0.3096811755776317, ('schrecklichen', 'seen'): 0.061827983226750184, ('naturkatastrophen', 'seen'): 0.061827983226750184, ('geworden', 'seen'): 0.061827983226750184}\n",
      "Alignment::  [(0, 0), (1, 3), (2, 6), (3, 6), (4, 1), (5, 23), (6, 24), (7, 6), (8, 6), (9, 6), (10, 6), (11, 34), (12, 6), (13, 36), (14, 6), (15, 6), (16, 6), (17, 25), (18, 6), (19, 6), (20, 6), (21, 10), (22, 6), (23, 6), (24, 6), (25, 36)]\n"
     ]
    }
   ],
   "source": [
    "alignemdWord, alignment = calculateAlignment(translationProb, pairs[:3])\n",
    "for index, a in enumerate(alignemdWord):\n",
    "    print(\"Alignment Probability:: \",a)\n",
    "    print(\"Alignment:: \", alignment[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, The word alignment and probability is printed in following format for each sentence pair:\n",
    "\n",
    "word alignment probability- **(german, english) : probability**.\n",
    "\n",
    "word alignment- **(germanWordIndex, englishWordIndex)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "frenchText = load_file('fr-en/fr-en.fr')\n",
    "englishText = load_file('fr-en/fr-en.en')\n",
    "pairs = generatePair(englishText, frenchText)\n",
    "\n",
    "# 0.0001 is the threshold to measure convergence\n",
    "translationProb = calculateTranslationProbability(pairs[:100], 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment Probability::  {('reprise', 'session'): 0.7126420590572695, ('de', 'of'): 0.5105043147838677, ('la', 'the'): 0.39854929347455204, ('session', 'resumption'): 0.5468638889694714}\n",
      "Alignment::  [(0, 3), (1, 1), (2, 2), (3, 0)]\n",
      "Alignment Probability::  {('je', 'i'): 1.0, ('déclare', 'declare'): 0.05593406909767865, ('reprise', 'session'): 0.7126420590572695, ('la', 'the'): 0.39854929347455204, ('session', 'year'): 0.4252866183196726, ('du', 'the'): 0.1623967140682424, ('parlement', 'parliament'): 0.9999999999777522, ('européen', 'declare'): 0.05498054657744576, ('qui', 'european'): 0.626069872489693, ('avait', 'declare'): 0.05593406909767865, ('été', 'new'): 0.11552025597133657, ('interrompue', 'declare'): 0.05593406909767865, ('le', 'would'): 0.28630802310956666, ('vendredi', 'declare'): 0.05593406909767865, ('17', 'declare'): 0.05593406909767865, ('décembre', 'declare'): 0.05593406909767865, ('dernier', 'declare'): 0.05593406909767865, ('et', 'and'): 1.0, ('vous', 'you'): 0.9316631801817766, ('renouvelle', 'declare'): 0.05593406909767865, ('tous', 'declare'): 0.05593406909767865, ('mes', 'declare'): 0.05593406909767865, ('vux', 'declare'): 0.05593406909767865, ('en', 'wish'): 0.4999720601549555, ('espérant', 'declare'): 0.05593406909767865, ('que', 'that'): 0.659282047812315, ('avez', 'declare'): 0.05593406909767865, ('passé', 'declare'): 0.05593406909767865, ('de', 'of'): 0.5105043147838677, ('bonnes', 'declare'): 0.05593406909767865, ('vacances', 'declare'): 0.05593406909767865, ('.', '.'): 1.0}\n",
      "Alignment::  [(0, 0), (1, 1), (2, 4), (3, 3), (4, 28), (5, 3), (6, 8), (7, 1), (8, 7), (9, 1), (10, 27), (11, 1), (12, 18), (13, 1), (14, 1), (15, 1), (16, 1), (17, 16), (18, 0), (19, 24), (20, 1), (21, 1), (22, 1), (23, 1), (24, 23), (25, 1), (26, 32), (27, 24), (28, 1), (29, 1), (30, 5), (31, 1), (32, 1), (33, 39)]\n",
      "Alignment Probability::  {('comme', 'as'): 0.2681064939262771, ('vous', 'you'): 0.9316631801817766, ('avez', 'seen'): 0.04081317149240413, ('pu', 'seen'): 0.04081317149240413, ('le', 'still'): 0.43178328680062134, ('constater', 'seen'): 0.04081317149240413, (',', ','): 0.8605395226565516, ('grand', 'seen'): 0.04081317149240413, ('\"', 'seen'): 0.08162634298480825, ('bogue', 'seen'): 0.04081317149240413, ('de', 'of'): 0.5105043147838677, (\"l'\", 'in'): 0.5609904944000005, ('an', 'seen'): 0.04081317149240413, ('2000', 'seen'): 0.04081317149240413, ('ne', 'were'): 0.5084499243137997, (\"s'\", 'seen'): 0.04081317149240413, ('est', 'will'): 0.1529560772420523, ('pas', 'seen'): 0.04081317149240413, ('produit', 'seen'): 0.04081317149240413, ('.', '.'): 1.0, ('en', 'as'): 0.31826235646648743, ('revanche', 'seen'): 0.04081317149240413, ('les', 'although'): 0.502429149880528, ('citoyens', 'seen'): 0.04081317149240413, (\"d'\", 'people'): 0.4950434867103773, ('un', 'a'): 0.5712597579239984, ('certain', 'seen'): 0.04081317149240413, ('nombre', 'seen'): 0.04081317149240413, ('nos', 'still'): 0.04975409855554819, ('pays', 'countries'): 0.6518124054498059, ('ont', 'number'): 0.44623793076123686, ('été', 'number'): 0.5537620692387631, ('victimes', 'seen'): 0.04081317149240413, ('catastrophes', 'seen'): 0.04081317149240413, ('naturelles', 'seen'): 0.04081317149240413, ('qui', 'countries'): 0.34818759455019405, ('vraiment', 'seen'): 0.04081317149240413, ('terribles', 'seen'): 0.04081317149240413}\n",
      "Alignment::  [(0, 2), (1, 3), (2, 6), (3, 6), (4, 18), (5, 6), (6, 1), (7, 18), (8, 6), (9, 6), (10, 6), (11, 24), (12, 21), (13, 6), (14, 6), (15, 6), (16, 34), (17, 6), (18, 4), (19, 6), (20, 6), (21, 36), (22, 2), (23, 6), (24, 1), (25, 0), (26, 6), (27, 20), (28, 22), (29, 6), (30, 6), (31, 24), (32, 18), (33, 25), (34, 23), (35, 23), (36, 6), (37, 24), (38, 6), (39, 6), (40, 25), (41, 23), (42, 6), (43, 23), (44, 6), (45, 36)]\n"
     ]
    }
   ],
   "source": [
    "alignemdWord, alignment = calculateAlignment(translationProb, pairs[:3])\n",
    "\n",
    "for index, a in enumerate(alignemdWord):\n",
    "    print(\"Alignment Probability:: \",a)\n",
    "    print(\"Alignment:: \", alignment[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, The word alignment and probability is printed in following format for each sentence pair:\n",
    "\n",
    "word alignment probability- **(french, english) : probability**.\n",
    "\n",
    "word alignment- **(frenchWordIndex, englishWordIndex)**\n",
    "\n",
    "The IBM 1 model is ran on 100 sentence pair. Please change line 6 above **translationProb = calculateTranslationProbability(pairs[:100], 0.0001)** to **translationProb = calculateTranslationProbability(pairs, 0.0001)** to run it for all sentence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
