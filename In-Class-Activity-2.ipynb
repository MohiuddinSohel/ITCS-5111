{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "import nltk as nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.stem import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice = nltk.corpus.gutenberg.raw('carroll-alice.txt')\n",
    "words = nltk.word_tokenize(alice)\n",
    "#print(alice)\n",
    "words = [word.lower() for word in words if word.isalpha()]\n",
    "#print(words)\n",
    "#counters = nltk.FreqDist(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'twice': 'twice', 'it': 'it', 'as': 'as', 'natural': 'natur', 'took': 'took', 'much': 'much', 'very': 'veri', 'she': 'she', 'day': 'day', 'watch': 'watch', 'out': 'out', 'no': 'no', 'use': 'use', 'made': 'made', 'looked': 'look', 'over': 'over', 'think': 'think', 'to': 'to', 'time': 'time', 'hurried': 'hurri', 'at': 'at', 'afterwards': 'afterward', 'mind': 'mind', 'a': 'a', 'but': 'but', 'picking': 'pick', 'ought': 'ought', 'getting': 'get', 'have': 'have', 'up': 'up', 'sitting': 'sit', 'in': 'in', 'that': 'that', 'beginning': 'begin', 'the': 'the', 'nor': 'nor', 'pleasure': 'pleasur', 'by': 'by', 'down': 'down', 'nothing': 'noth', 'would': 'would', 'so': 'so', 'had': 'had', 'or': 'or', 'all': 'all', 'remarkable': 'remark', 'oh': 'oh', 'pink': 'pink', 'of': 'of', 'sleepy': 'sleepi', 'this': 'thi', 'was': 'wa', 'ran': 'ran', 'into': 'into', 'own': 'own', 'say': 'say', 'having': 'have', 'stupid': 'stupid', 'get': 'get', 'thought': 'thought', 'her': 'her', 'reading': 'read', 'lewis': 'lewi', 'wonderland': 'wonderland', 'book': 'book', 'worth': 'worth', 'what': 'what', 'trouble': 'troubl', 'and': 'and', 'for': 'for', 'carroll': 'carrol', 'tired': 'tire', 'conversation': 'convers', 'did': 'did', 'dear': 'dear', 'i': 'i', 'way': 'way', 'peeped': 'peep', 'once': 'onc', 'with': 'with', 'be': 'be', 'late': 'late', 'conversations': 'convers', 'occurred': 'occur', 'rabbit': 'rabbit', 'seemed': 'seem', 'when': 'when', 'well': 'well', 'shall': 'shall', 'could': 'could', 'alice': 'alic', 'considering': 'consid', 'there': 'there', 'quite': 'quit', 'daisies': 'daisi', 'itself': 'itself', 'eyes': 'eye', 'whether': 'whether', 'adventures': 'adventur', 'white': 'white', 'feel': 'feel', 'actually': 'actual', 'its': 'it', 'pictures': 'pictur', 'suddenly': 'suddenli', 'on': 'on', 'sister': 'sister', 'close': 'close', 'making': 'make', 'do': 'do', 'hear': 'hear', 'chapter': 'chapter', 'bank': 'bank', 'is': 'is', 'hot': 'hot', 'wondered': 'wonder', 'then': 'then'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "portStemmer = PorterStemmer()\n",
    "portStemmerList = {}\n",
    "for i in range(200):\n",
    "    portStemmerList[words[i]] = portStemmer.stem(words[i])\n",
    "print(portStemmerList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'twice': 'twice', 'it': 'it', 'as': 'a', 'natural': 'natural', 'took': 'took', 'much': 'much', 'very': 'very', 'she': 'she', 'day': 'day', 'watch': 'watch', 'out': 'out', 'no': 'no', 'use': 'use', 'made': 'made', 'looked': 'looked', 'over': 'over', 'think': 'think', 'to': 'to', 'time': 'time', 'hurried': 'hurried', 'at': 'at', 'afterwards': 'afterwards', 'mind': 'mind', 'a': 'a', 'but': 'but', 'picking': 'picking', 'ought': 'ought', 'getting': 'getting', 'have': 'have', 'up': 'up', 'sitting': 'sitting', 'in': 'in', 'that': 'that', 'beginning': 'beginning', 'the': 'the', 'nor': 'nor', 'pleasure': 'pleasure', 'by': 'by', 'down': 'down', 'nothing': 'nothing', 'would': 'would', 'so': 'so', 'had': 'had', 'or': 'or', 'all': 'all', 'remarkable': 'remarkable', 'oh': 'oh', 'pink': 'pink', 'of': 'of', 'sleepy': 'sleepy', 'this': 'this', 'was': 'wa', 'ran': 'ran', 'into': 'into', 'own': 'own', 'say': 'say', 'having': 'having', 'stupid': 'stupid', 'get': 'get', 'thought': 'thought', 'her': 'her', 'reading': 'reading', 'lewis': 'lewis', 'wonderland': 'wonderland', 'book': 'book', 'worth': 'worth', 'what': 'what', 'trouble': 'trouble', 'and': 'and', 'for': 'for', 'carroll': 'carroll', 'tired': 'tired', 'conversation': 'conversation', 'did': 'did', 'dear': 'dear', 'i': 'i', 'way': 'way', 'peeped': 'peeped', 'once': 'once', 'with': 'with', 'be': 'be', 'late': 'late', 'conversations': 'conversation', 'occurred': 'occurred', 'rabbit': 'rabbit', 'seemed': 'seemed', 'when': 'when', 'well': 'well', 'shall': 'shall', 'could': 'could', 'alice': 'alice', 'considering': 'considering', 'there': 'there', 'quite': 'quite', 'daisies': 'daisy', 'itself': 'itself', 'eyes': 'eye', 'whether': 'whether', 'adventures': 'adventure', 'white': 'white', 'feel': 'feel', 'actually': 'actually', 'its': 'it', 'pictures': 'picture', 'suddenly': 'suddenly', 'on': 'on', 'sister': 'sister', 'close': 'close', 'making': 'making', 'do': 'do', 'hear': 'hear', 'chapter': 'chapter', 'bank': 'bank', 'is': 'is', 'hot': 'hot', 'wondered': 'wondered', 'then': 'then'}\n"
     ]
    }
   ],
   "source": [
    "wordLemitizerStemmer = WordNetLemmatizer()\n",
    "wordLemitizerStemmerList = {}\n",
    "for i in range(200):\n",
    "    wordLemitizerStemmerList[words[i]] = wordLemitizerStemmer.lemmatize(words[i])\n",
    "print(wordLemitizerStemmerList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'twice': 'twic', 'it': 'it', 'as': 'as', 'natural': 'nat', 'took': 'took', 'much': 'much', 'very': 'very', 'she': 'she', 'day': 'day', 'watch': 'watch', 'out': 'out', 'no': 'no', 'use': 'us', 'made': 'mad', 'looked': 'look', 'over': 'ov', 'think': 'think', 'to': 'to', 'time': 'tim', 'hurried': 'hurry', 'at': 'at', 'afterwards': 'afterward', 'mind': 'mind', 'a': 'a', 'but': 'but', 'picking': 'pick', 'ought': 'ought', 'getting': 'get', 'have': 'hav', 'up': 'up', 'sitting': 'sit', 'in': 'in', 'that': 'that', 'beginning': 'begin', 'the': 'the', 'nor': 'nor', 'pleasure': 'pleas', 'by': 'by', 'down': 'down', 'nothing': 'noth', 'would': 'would', 'so': 'so', 'had': 'had', 'or': 'or', 'all': 'al', 'remarkable': 'remark', 'oh': 'oh', 'pink': 'pink', 'of': 'of', 'sleepy': 'sleepy', 'this': 'thi', 'was': 'was', 'ran': 'ran', 'into': 'into', 'own': 'own', 'say': 'say', 'having': 'hav', 'stupid': 'stupid', 'get': 'get', 'thought': 'thought', 'her': 'her', 'reading': 'read', 'lewis': 'lew', 'wonderland': 'wonderland', 'book': 'book', 'worth': 'wor', 'what': 'what', 'trouble': 'troubl', 'and': 'and', 'for': 'for', 'carroll': 'carrol', 'tired': 'tir', 'conversation': 'convers', 'did': 'did', 'dear': 'dear', 'i': 'i', 'way': 'way', 'peeped': 'peep', 'once': 'ont', 'with': 'with', 'be': 'be', 'late': 'lat', 'conversations': 'convers', 'occurred': 'occur', 'rabbit': 'rabbit', 'seemed': 'seem', 'when': 'when', 'well': 'wel', 'shall': 'shal', 'could': 'could', 'alice': 'al', 'considering': 'consid', 'there': 'ther', 'quite': 'quit', 'daisies': 'daisy', 'itself': 'itself', 'eyes': 'ey', 'whether': 'wheth', 'adventures': 'adv', 'white': 'whit', 'feel': 'feel', 'actually': 'act', 'its': 'it', 'pictures': 'pict', 'suddenly': 'sud', 'on': 'on', 'sister': 'sist', 'close': 'clos', 'making': 'mak', 'do': 'do', 'hear': 'hear', 'chapter': 'chapt', 'bank': 'bank', 'is': 'is', 'hot': 'hot', 'wondered': 'wond', 'then': 'then'}\n",
      "abandon\n",
      "abandon\n"
     ]
    }
   ],
   "source": [
    "lancasterStemmer = LancasterStemmer()\n",
    "lancasterStemmerList = {}\n",
    "for i in range(200):\n",
    "    lancasterStemmerList[words[i]] = lancasterStemmer.stem(words[i])\n",
    "print(lancasterStemmerList)\n",
    "\n",
    "print(portStemmer.stem(\"abandonment\"))\n",
    "print(portStemmer.stem(\"abandonment\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  LancasterStemmer :       'twice': 'twic'   'natural': 'nat'  'use': 'us'  'picking': 'pick'\n",
    "###### PorterStemmer: 'twice':   'twice', 'as': 'as', 'natural': 'natur' 'very': 'veri' 'picking': 'picking'\n",
    "### Reason\n",
    "PorterStemer does not reduce present participle form may be to keep context such as picking:picking.\n",
    "LancasterStemmer seems to choose smaller length root word 'natural': 'nat' 'twice': 'twic' working in a aggresive manner\n",
    "\n",
    "###### WordNetLemmatizer: 'twice': 'twice'  'natural': 'natural' 'as': 'a' 'picking': 'picking'\n",
    "\n",
    "### Advangtage:\n",
    "Doing stemming will make the feature space small making information retrival easier which is used in search engines to manage queries\n",
    "### Disadvantage:\n",
    "Doing stemming will discard context of word creating ambiguty which will make sentiment analysis difficult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abandon\n",
      "abandon\n",
      "absorb\n",
      "absorb\n",
      "market\n",
      "market\n",
      "univers\n",
      "univers\n",
      "volum\n",
      "volum\n"
     ]
    }
   ],
   "source": [
    "print(portStemmer.stem(\"abandonment\"))\n",
    "print(portStemmer.stem(\"abandon\"))\n",
    "\n",
    "print(portStemmer.stem(\"absorbency\"))\n",
    "print(portStemmer.stem(\"absorbent\"))\n",
    "\n",
    "print(portStemmer.stem(\"marketing\"))\n",
    "print(portStemmer.stem(\"markets\"))\n",
    "\n",
    "print(portStemmer.stem(\"university\"))\n",
    "print(portStemmer.stem(\"universe\"))\n",
    "\n",
    "print(portStemmer.stem(\"volume\"))\n",
    "print(portStemmer.stem(\"volumes\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pair 4 which is university/universe should not be conflated. Additionally pair 5  is wrong the stemmed word should be volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trojan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'trojan/agent'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordLemitizerStemmer = WordNetLemmatizer()\n",
    "print(wordLemitizerStemmer.lemmatize(\"trojans\"))\n",
    "wordLemitizerStemmer.lemmatize(\"trojan/agent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
